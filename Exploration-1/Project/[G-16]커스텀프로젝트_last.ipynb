{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89262939",
   "metadata": {},
   "source": [
    "# [G-16] 커스텀프로젝트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3421109b",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a30af6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting scikit-multilearn\n",
      "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
      "     |████████████████████████████████| 89 kB 4.3 MB/s            \n",
      "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
      "Successfully installed scikit-multilearn-0.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install scikit-multilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cbff25b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow as tf\n",
    "import sentencepiece as spm\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, AdamW, AutoModelForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset, DatasetDict\n",
    "from datasets import load_metric\n",
    "from datasets import ClassLabel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8351a0c7",
   "metadata": {},
   "source": [
    "## Step1 : Data 불러오기 및 전처리 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bda4bc6",
   "metadata": {},
   "source": [
    "### data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e227631",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_table(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\")\n",
    "test_data = pd.read_table(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5b24520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb6346b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9274899</td>\n",
       "      <td>GDNTOPCLASSINTHECLUB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           document  label\n",
       "0  6270596                                                굳 ㅋ      1\n",
       "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
       "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
       "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
       "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3be5a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data['document'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a57835a",
   "metadata": {},
   "source": [
    "### 문자 길이 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c8352db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_len(sentence):\n",
    "    st_len = []\n",
    "    for i in range(len(sentence['document'])):\n",
    "        st_test_len = len(str(sentence['document'][i]))\n",
    "        st_len.append(st_test_len)\n",
    "        \n",
    "    print(\"최대 길이 값 : \", max(st_len))\n",
    "    print(\"최소 길이 값 : \", min(st_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2df31acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 길이 값 :  146\n",
      "최소 길이 값 :  1\n"
     ]
    }
   ],
   "source": [
    "sentence_len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e80ca32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 길이 값 :  144\n",
      "최소 길이 값 :  1\n"
     ]
    }
   ],
   "source": [
    "sentence_len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab54c65",
   "metadata": {},
   "source": [
    "### 결측값 확인 및 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2d3a130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          0\n",
      "document    5\n",
      "label       0\n",
      "dtype: int64\n",
      "--------------\n",
      "id          0\n",
      "document    3\n",
      "label       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().sum())\n",
    "print('--------------')\n",
    "print(test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c57ed87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "msno.matrix(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48e66174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "msno.matrix(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a236fe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dropna(axis=0, how='any', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61dd101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.dropna(axis=0, how='any', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "214fbbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          0\n",
      "document    0\n",
      "label       0\n",
      "dtype: int64\n",
      "--------------\n",
      "id          0\n",
      "document    0\n",
      "label       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().sum())\n",
    "print('--------------')\n",
    "print(test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f1818b",
   "metadata": {},
   "source": [
    "### 중복제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edc73863",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop_duplicates(['document'], keep='first', inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86f22c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146182 entries, 0 to 146181\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        146182 non-null  int64 \n",
      " 1   document  146182 non-null  object\n",
      " 2   label     146182 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "653fcc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop_duplicates(['document'], keep='first', inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3249d72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49157 entries, 0 to 49156\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        49157 non-null  int64 \n",
      " 1   document  49157 non-null  object\n",
      " 2   label     49157 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfc2457e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 길이 값 :  146\n",
      "최소 길이 값 :  1\n"
     ]
    }
   ],
   "source": [
    "sentence_len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f85e674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 길이 값 :  144\n",
      "최소 길이 값 :  1\n"
     ]
    }
   ],
   "source": [
    "sentence_len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15676ed4",
   "metadata": {},
   "source": [
    "## Step2 : Tokenizing (Sentence piece or klue/bert-base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849e0434",
   "metadata": {},
   "source": [
    "### Tokenizing 전 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4c46bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_doc = np.concatenate((train_data['document'].values,test_data['document'].values))\n",
    "\n",
    "def clean_sentence(sentence):\n",
    "        sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "        sentence = re.sub(r'[\" \"]+', \" \", sentence) \n",
    "        sentence = re.sub(r\"[^ㄱ-ㅎ가-힣a-zA-Z!.,?]+\", \" \", sentence)\n",
    "        return sentence\n",
    "\n",
    "filtered_corpus = []\n",
    "for i in all_doc :\n",
    "    sentence = clean_sentence(i)\n",
    "    filtered_corpus.append(sentence)\n",
    "\n",
    "train_f = filtered_corpus[:146182]\n",
    "test_f = filtered_corpus[146182:]\n",
    "all_doc_f = np.concatenate((train_f,test_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af546c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['아 더빙 . . 진짜 짜증나네요 목소리', '흠 . . . 포스터보고 초딩영화줄 . . . . 오버연기조차 가볍지 않구나', '너무재밓었다그래서보는것을추천한다', '교도소 이야기구먼 . . 솔직히 재미는 없다 . . 평점 조정', '사이몬페그의 익살스런 연기가 돋보였던 영화 ! 스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다']\n",
      "------------------------------\n",
      "['굳 ㅋ', 'GDNTOPCLASSINTHECLUB', '뭐야 이 평점들은 . . . . 나쁘진 않지만 점 짜리는 더더욱 아니잖아', '지루하지는 않은데 완전 막장임 . . . 돈주고 보기에는 . . . . ', ' D만 아니었어도 별 다섯 개 줬을텐데 . . 왜 D로 나와서 제 심기를 불편하게 하죠 ? ? ']\n"
     ]
    }
   ],
   "source": [
    "print(train_f[:5])\n",
    "print('------------------------------')\n",
    "print(test_f[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93eb2424",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.txt', 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(all_doc_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4180eab9",
   "metadata": {},
   "source": [
    "### sentence piece tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f922d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=test.txt --model_prefix=st_data --vocab_size=35000 --model_type=char --max_sentence_length=9999\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: test.txt\n",
      "  input_format: \n",
      "  model_prefix: st_data\n",
      "  model_type: CHAR\n",
      "  vocab_size: 35000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 9999\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: test.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 195339 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=7529126\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9501% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1560\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999501\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 195204 sentences.\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: st_data.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: st_data.vocab\n"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.Train('--input=test.txt --model_prefix=st_data --vocab_size=35000 --model_type=char --max_sentence_length=9999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21021c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "vocab_file = \"st_data.model\"\n",
    "sp.load(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2097264f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', '오', '늘', '의', '▁', '날', '씨', '는', '▁', '맑', '아', '요']\n"
     ]
    }
   ],
   "source": [
    "test_sentence_piece = \"오늘의 날씨는 맑아요\"\n",
    "print(sp.encode_as_pieces(test_sentence_piece))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e8d794",
   "metadata": {},
   "source": [
    "### klue/bert-base tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f38ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"klue/bert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea97e6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '오늘', '##의', '날씨', '##는', '맑', '##아', '##요', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "test_klue_bert = \"오늘의 날씨는 맑아요\"\n",
    "test_klue = tokenizer(test_klue_bert).tokens()\n",
    "print(test_klue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66696a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPECIAL_TOKENS_ATTRIBUTES',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_tokens',\n",
       " '_additional_special_tokens',\n",
       " '_batch_encode_plus',\n",
       " '_bos_token',\n",
       " '_cls_token',\n",
       " '_convert_encoding',\n",
       " '_convert_id_to_token',\n",
       " '_convert_token_to_id_with_added_voc',\n",
       " '_create_or_get_repo',\n",
       " '_decode',\n",
       " '_decode_use_source_tokenizer',\n",
       " '_encode_plus',\n",
       " '_eos_token',\n",
       " '_eventual_warn_about_too_long_sequence',\n",
       " '_from_pretrained',\n",
       " '_get_padding_truncation_strategies',\n",
       " '_get_repo_url_from_name',\n",
       " '_mask_token',\n",
       " '_pad',\n",
       " '_pad_token',\n",
       " '_pad_token_type_id',\n",
       " '_push_to_hub',\n",
       " '_save_pretrained',\n",
       " '_sep_token',\n",
       " '_tokenizer',\n",
       " '_unk_token',\n",
       " 'add_special_tokens',\n",
       " 'add_tokens',\n",
       " 'additional_special_tokens',\n",
       " 'additional_special_tokens_ids',\n",
       " 'all_special_ids',\n",
       " 'all_special_tokens',\n",
       " 'all_special_tokens_extended',\n",
       " 'as_target_tokenizer',\n",
       " 'backend_tokenizer',\n",
       " 'batch_decode',\n",
       " 'batch_encode_plus',\n",
       " 'bos_token',\n",
       " 'bos_token_id',\n",
       " 'build_inputs_with_special_tokens',\n",
       " 'can_save_slow_tokenizer',\n",
       " 'clean_up_tokenization',\n",
       " 'cls_token',\n",
       " 'cls_token_id',\n",
       " 'convert_ids_to_tokens',\n",
       " 'convert_tokens_to_ids',\n",
       " 'convert_tokens_to_string',\n",
       " 'create_token_type_ids_from_sequences',\n",
       " 'decode',\n",
       " 'decoder',\n",
       " 'deprecation_warnings',\n",
       " 'do_lower_case',\n",
       " 'encode',\n",
       " 'encode_plus',\n",
       " 'eos_token',\n",
       " 'eos_token_id',\n",
       " 'from_pretrained',\n",
       " 'get_added_vocab',\n",
       " 'get_special_tokens_mask',\n",
       " 'get_vocab',\n",
       " 'init_inputs',\n",
       " 'init_kwargs',\n",
       " 'is_fast',\n",
       " 'mask_token',\n",
       " 'mask_token_id',\n",
       " 'max_len_sentences_pair',\n",
       " 'max_len_single_sentence',\n",
       " 'max_model_input_sizes',\n",
       " 'model_input_names',\n",
       " 'model_max_length',\n",
       " 'name_or_path',\n",
       " 'num_special_tokens_to_add',\n",
       " 'pad',\n",
       " 'pad_token',\n",
       " 'pad_token_id',\n",
       " 'pad_token_type_id',\n",
       " 'padding_side',\n",
       " 'prepare_for_model',\n",
       " 'prepare_seq2seq_batch',\n",
       " 'pretrained_init_configuration',\n",
       " 'pretrained_vocab_files_map',\n",
       " 'push_to_hub',\n",
       " 'sanitize_special_tokens',\n",
       " 'save_pretrained',\n",
       " 'save_vocabulary',\n",
       " 'sep_token',\n",
       " 'sep_token_id',\n",
       " 'set_truncation_and_padding',\n",
       " 'slow_tokenizer_class',\n",
       " 'special_tokens_map',\n",
       " 'special_tokens_map_extended',\n",
       " 'tokenize',\n",
       " 'train_new_from_iterator',\n",
       " 'truncate_sequences',\n",
       " 'unk_token',\n",
       " 'unk_token_id',\n",
       " 'verbose',\n",
       " 'vocab',\n",
       " 'vocab_files_names',\n",
       " 'vocab_size']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "930343fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(train_f) == len(train_data['label']))\n",
    "print(len(test_f) == len(test_data['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "542265f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aca206e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3aedf833",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = pd.DataFrame({'values' : train_f, 'label' : train_data['label']}).reset_index(drop=True)\n",
    "test_ = pd.DataFrame({'values' : test_f, 'label' : test_data['label']}).reset_index(drop=True)\n",
    "\n",
    "# 데이터줄이기...\n",
    "train_ = train_.sample(15000, random_state=123).reset_index(drop=True)\n",
    "test_ = test_.sample(1000, random_state=123).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70469737",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d = Dataset.from_pandas(train_)\n",
    "test_d = Dataset.from_pandas(test_)\n",
    "\n",
    "# datasetdict형태로 transformation\n",
    "dataset = datasets.DatasetDict({\"train\":train_d,\"test\":test_d})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09739430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#int2str 사용 가능하게 label 값을 classlabel 객채로 변환, \n",
    "dataset['train'].features['label'] = ClassLabel(\n",
    "    num_classes=2, \n",
    "    names=['negative','positive'])\n",
    "\n",
    "dataset['test'].features['label'] = ClassLabel(\n",
    "    num_classes=2, \n",
    "    names=['negative','positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd422a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 값 최종 확인\n",
    "dataset.set_format(type='pandas')\n",
    "df = dataset['train'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab4f172d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>세월을 무시하는 상콤한 하이틴무비</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>일베충은 보고 반성할것</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>대만ㅅㅁ섬짱개들 이따구 쓰레기영화 만들거잇네이따걸왜 상영허냐 ! ! !</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>역시 한국 영화다 보니까 스토리가좀</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>평점을 보니 초딩들에게는 점짜리 영화인 듯</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     values  label label_name\n",
       "0                        세월을 무시하는 상콤한 하이틴무비      1   positive\n",
       "1                              일베충은 보고 반성할것      1   positive\n",
       "2  대만ㅅㅁ섬짱개들 이따구 쓰레기영화 만들거잇네이따걸왜 상영허냐 ! ! !       0   negative\n",
       "3                      역시 한국 영화다 보니까 스토리가좀       0   negative\n",
       "4                  평점을 보니 초딩들에게는 점짜리 영화인 듯       0   negative"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_int2str(row):\n",
    "    return dataset[\"train\"].features[\"label\"].int2str(row)\n",
    "\n",
    "df[\"label_name\"] = df[\"label\"].apply(label_int2str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d3bc27fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩하여 최종 데이터 dict 저장\n",
    "dataset.set_format(type=None)\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['values'], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3451e8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73f639975d94d759386a92724403456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833ad98c6cc94b7694ac19eb6aa75683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_encoded = dataset.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6bed289b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': ['attention_mask', 'input_ids', 'label', 'token_type_ids', 'values'], 'test': ['attention_mask', 'input_ids', 'label', 'token_type_ids', 'values']}\n",
      "['attention_mask', 'input_ids', 'label', 'token_type_ids', 'values']\n"
     ]
    }
   ],
   "source": [
    "print(dataset_encoded.column_names)\n",
    "print(dataset_encoded[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a08c4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator =  DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a570b6",
   "metadata": {},
   "source": [
    "## Step3 : Model (klue/bert-base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d54bbe2",
   "metadata": {},
   "source": [
    "### BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c73e2a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_ckpt = \"klue/bert-base\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcf2aba",
   "metadata": {},
   "source": [
    "### hidden states 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3d5b7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hidden_states(batch):\n",
    "    # 모델 입력 -> GPU\n",
    "    inputs = {k:v for k,v in batch.items()\n",
    "              if k in tokenizer.model_input_names}\n",
    "    # hidden states 출력\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state\n",
    "    return {\"hidden_state\": last_hidden_state[:,0].cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7c78352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_encoded.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed6d1dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CPU에 있는 텐서 \n",
    "# dataset_encoded.is_cuda  # returns False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2899cd8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e0c1f80093454f9cf8d13325b2a093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c41a56bf65c4dcbb04ba3071e26b1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_hidden = dataset_encoded.map(extract_hidden_states, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da3828b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['attention_mask',\n",
       "  'hidden_state',\n",
       "  'input_ids',\n",
       "  'label',\n",
       "  'token_type_ids',\n",
       "  'values'],\n",
       " 'test': ['attention_mask',\n",
       "  'hidden_state',\n",
       "  'input_ids',\n",
       "  'label',\n",
       "  'token_type_ids',\n",
       "  'values']}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_hidden.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0741bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attention_mask',\n",
       " 'hidden_state',\n",
       " 'input_ids',\n",
       " 'label',\n",
       " 'token_type_ids',\n",
       " 'values']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_hidden[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0dd874da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
      "        0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "        1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "        1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
      "        0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(dataset_hidden[\"test\"][\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b5f4ee",
   "metadata": {},
   "source": [
    "### 나이브 베이즈 모델 (Base model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0c6680f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "macro_scores, micro_scores = defaultdict(list), defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e6dcded6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 768) (1000, 768)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(dataset_hidden['train']['hidden_state'])\n",
    "X_valid = np.array(dataset_hidden['test']['hidden_state'])\n",
    "y_train = np.array(dataset_hidden['train']['label'])\n",
    "y_valid = np.array(dataset_hidden['test']['label'])\n",
    "print(X_train.shape, X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5c031ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = BernoulliNB()\n",
    "base_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6f836f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80       528\n",
      "           1       0.79      0.75      0.77       472\n",
      "\n",
      "    accuracy                           0.79      1000\n",
      "   macro avg       0.79      0.78      0.78      1000\n",
      "weighted avg       0.79      0.79      0.79      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = base_model.predict(X_valid)\n",
    "classification = classification_report(y_valid, prediction)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf31ff1",
   "metadata": {},
   "source": [
    "### Finetuning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2d82ae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 2\n",
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "model_ckpt = \"klue/bert-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ee204673",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "dataset_config = AutoConfig.from_pretrained(model_ckpt,\n",
    "                                            num_labels = num_labels,\n",
    "                                            id2label = id2label,\n",
    "                                            label2id = label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4e621ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, \n",
    "                                                           config=dataset_config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "64aa94d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir = 'data_test',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    save_steps=1e6,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    disable_tqdm=True,\n",
    "    load_best_model_at_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4ed55657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\" : acc, \"f1\" : f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "51f767eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_ckpt, config=dataset_config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "651fac5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/klue/bert-base/resolve/main/pytorch_model.bin from cache at /aiffel/.cache/huggingface/transformers/05b36ee62545d769939a7746eca739b844a40a7a7553700f110b58b28ed6a949.7cb231256a5dbe886e12b902d05cb1241f330d8c19428508f91b2b28c1cfe0b6\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset_encoded[\"train\"],\n",
    "    eval_dataset=dataset_encoded[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3b344b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5529d329",
   "metadata": {},
   "source": [
    "* 메모리 확보 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1fe5a6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/klue/bert-base/resolve/main/pytorch_model.bin from cache at /aiffel/.cache/huggingface/transformers/05b36ee62545d769939a7746eca739b844a40a7a7553700f110b58b28ed6a949.7cb231256a5dbe886e12b902d05cb1241f330d8c19428508f91b2b28c1cfe0b6\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: values.\n",
      "***** Running training *****\n",
      "  Num examples = 15000\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2345\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: values.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to data_test/checkpoint-469\n",
      "Configuration saved in data_test/checkpoint-469/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3204146921634674, 'eval_accuracy': 0.86, 'eval_f1': 0.8600897435897437, 'eval_runtime': 6.2246, 'eval_samples_per_second': 160.653, 'eval_steps_per_second': 5.141, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in data_test/checkpoint-469/pytorch_model.bin\n",
      "tokenizer config file saved in data_test/checkpoint-469/tokenizer_config.json\n",
      "Special tokens file saved in data_test/checkpoint-469/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3534, 'learning_rate': 1.5735607675906184e-05, 'epoch': 1.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: values.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to data_test/checkpoint-938\n",
      "Configuration saved in data_test/checkpoint-938/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3466455042362213, 'eval_accuracy': 0.86, 'eval_f1': 0.8601047707090232, 'eval_runtime': 6.1281, 'eval_samples_per_second': 163.183, 'eval_steps_per_second': 5.222, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in data_test/checkpoint-938/pytorch_model.bin\n",
      "tokenizer config file saved in data_test/checkpoint-938/tokenizer_config.json\n",
      "Special tokens file saved in data_test/checkpoint-938/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2169, 'learning_rate': 1.1471215351812369e-05, 'epoch': 2.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: values.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to data_test/checkpoint-1407\n",
      "Configuration saved in data_test/checkpoint-1407/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4347712993621826, 'eval_accuracy': 0.853, 'eval_f1': 0.8529136401295473, 'eval_runtime': 6.1181, 'eval_samples_per_second': 163.448, 'eval_steps_per_second': 5.23, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in data_test/checkpoint-1407/pytorch_model.bin\n",
      "tokenizer config file saved in data_test/checkpoint-1407/tokenizer_config.json\n",
      "Special tokens file saved in data_test/checkpoint-1407/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1364, 'learning_rate': 7.20682302771855e-06, 'epoch': 3.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: values.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to data_test/checkpoint-1876\n",
      "Configuration saved in data_test/checkpoint-1876/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5393721461296082, 'eval_accuracy': 0.861, 'eval_f1': 0.8611056160158413, 'eval_runtime': 6.1202, 'eval_samples_per_second': 163.393, 'eval_steps_per_second': 5.229, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in data_test/checkpoint-1876/pytorch_model.bin\n",
      "tokenizer config file saved in data_test/checkpoint-1876/tokenizer_config.json\n",
      "Special tokens file saved in data_test/checkpoint-1876/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0782, 'learning_rate': 2.9424307036247335e-06, 'epoch': 4.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: values.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to data_test/checkpoint-2345\n",
      "Configuration saved in data_test/checkpoint-2345/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5843184590339661, 'eval_accuracy': 0.862, 'eval_f1': 0.8621077128138622, 'eval_runtime': 6.0973, 'eval_samples_per_second': 164.007, 'eval_steps_per_second': 5.248, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in data_test/checkpoint-2345/pytorch_model.bin\n",
      "tokenizer config file saved in data_test/checkpoint-2345/tokenizer_config.json\n",
      "Special tokens file saved in data_test/checkpoint-2345/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from data_test/checkpoint-469 (score: 0.3204146921634674).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1549.8637, 'train_samples_per_second': 48.391, 'train_steps_per_second': 1.513, 'train_loss': 0.17691892693037672, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2345, training_loss=0.17691892693037672, metrics={'train_runtime': 1549.8637, 'train_samples_per_second': 48.391, 'train_steps_per_second': 1.513, 'train_loss': 0.17691892693037672, 'epoch': 5.0})"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f3da28f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af02ad7",
   "metadata": {},
   "source": [
    "* 메모리 공간 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "08f52429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_run = trainer.hyperparameter_search(n_trials=10, direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7dd35c",
   "metadata": {},
   "source": [
    "* n_trials를 조절하여 grid search를 하는 횟수를 조절 가능(https://dacon.io/en/competitions/official/235747/codeshare/3047?page=1&dtype=recent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb5f47f",
   "metadata": {},
   "source": [
    "### Freezing test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3ab9e516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/klue/bert-base/resolve/main/pytorch_model.bin from cache at /aiffel/.cache/huggingface/transformers/05b36ee62545d769939a7746eca739b844a40a7a7553700f110b58b28ed6a949.7cb231256a5dbe886e12b902d05cb1241f330d8c19428508f91b2b28c1cfe0b6\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight False\n",
      "bert.embeddings.position_embeddings.weight False\n",
      "bert.embeddings.token_type_embeddings.weight False\n",
      "bert.embeddings.LayerNorm.weight False\n",
      "bert.embeddings.LayerNorm.bias False\n",
      "bert.encoder.layer.0.attention.self.query.weight False\n",
      "bert.encoder.layer.0.attention.self.query.bias False\n",
      "bert.encoder.layer.0.attention.self.key.weight False\n",
      "bert.encoder.layer.0.attention.self.key.bias False\n",
      "bert.encoder.layer.0.attention.self.value.weight False\n",
      "bert.encoder.layer.0.attention.self.value.bias False\n",
      "bert.encoder.layer.0.attention.output.dense.weight False\n",
      "bert.encoder.layer.0.attention.output.dense.bias False\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight False\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias False\n",
      "bert.encoder.layer.0.intermediate.dense.weight False\n",
      "bert.encoder.layer.0.intermediate.dense.bias False\n",
      "bert.encoder.layer.0.output.dense.weight False\n",
      "bert.encoder.layer.0.output.dense.bias False\n",
      "bert.encoder.layer.0.output.LayerNorm.weight False\n",
      "bert.encoder.layer.0.output.LayerNorm.bias False\n",
      "bert.encoder.layer.1.attention.self.query.weight False\n",
      "bert.encoder.layer.1.attention.self.query.bias False\n",
      "bert.encoder.layer.1.attention.self.key.weight False\n",
      "bert.encoder.layer.1.attention.self.key.bias False\n",
      "bert.encoder.layer.1.attention.self.value.weight False\n",
      "bert.encoder.layer.1.attention.self.value.bias False\n",
      "bert.encoder.layer.1.attention.output.dense.weight False\n",
      "bert.encoder.layer.1.attention.output.dense.bias False\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight False\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias False\n",
      "bert.encoder.layer.1.intermediate.dense.weight False\n",
      "bert.encoder.layer.1.intermediate.dense.bias False\n",
      "bert.encoder.layer.1.output.dense.weight False\n",
      "bert.encoder.layer.1.output.dense.bias False\n",
      "bert.encoder.layer.1.output.LayerNorm.weight False\n",
      "bert.encoder.layer.1.output.LayerNorm.bias False\n",
      "bert.encoder.layer.2.attention.self.query.weight False\n",
      "bert.encoder.layer.2.attention.self.query.bias False\n",
      "bert.encoder.layer.2.attention.self.key.weight False\n",
      "bert.encoder.layer.2.attention.self.key.bias False\n",
      "bert.encoder.layer.2.attention.self.value.weight False\n",
      "bert.encoder.layer.2.attention.self.value.bias False\n",
      "bert.encoder.layer.2.attention.output.dense.weight False\n",
      "bert.encoder.layer.2.attention.output.dense.bias False\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight False\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias False\n",
      "bert.encoder.layer.2.intermediate.dense.weight False\n",
      "bert.encoder.layer.2.intermediate.dense.bias False\n",
      "bert.encoder.layer.2.output.dense.weight False\n",
      "bert.encoder.layer.2.output.dense.bias False\n",
      "bert.encoder.layer.2.output.LayerNorm.weight False\n",
      "bert.encoder.layer.2.output.LayerNorm.bias False\n",
      "bert.encoder.layer.3.attention.self.query.weight False\n",
      "bert.encoder.layer.3.attention.self.query.bias False\n",
      "bert.encoder.layer.3.attention.self.key.weight False\n",
      "bert.encoder.layer.3.attention.self.key.bias False\n",
      "bert.encoder.layer.3.attention.self.value.weight False\n",
      "bert.encoder.layer.3.attention.self.value.bias False\n",
      "bert.encoder.layer.3.attention.output.dense.weight False\n",
      "bert.encoder.layer.3.attention.output.dense.bias False\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight False\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias False\n",
      "bert.encoder.layer.3.intermediate.dense.weight False\n",
      "bert.encoder.layer.3.intermediate.dense.bias False\n",
      "bert.encoder.layer.3.output.dense.weight False\n",
      "bert.encoder.layer.3.output.dense.bias False\n",
      "bert.encoder.layer.3.output.LayerNorm.weight False\n",
      "bert.encoder.layer.3.output.LayerNorm.bias False\n",
      "bert.encoder.layer.4.attention.self.query.weight False\n",
      "bert.encoder.layer.4.attention.self.query.bias False\n",
      "bert.encoder.layer.4.attention.self.key.weight False\n",
      "bert.encoder.layer.4.attention.self.key.bias False\n",
      "bert.encoder.layer.4.attention.self.value.weight False\n",
      "bert.encoder.layer.4.attention.self.value.bias False\n",
      "bert.encoder.layer.4.attention.output.dense.weight False\n",
      "bert.encoder.layer.4.attention.output.dense.bias False\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight False\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias False\n",
      "bert.encoder.layer.4.intermediate.dense.weight False\n",
      "bert.encoder.layer.4.intermediate.dense.bias False\n",
      "bert.encoder.layer.4.output.dense.weight False\n",
      "bert.encoder.layer.4.output.dense.bias False\n",
      "bert.encoder.layer.4.output.LayerNorm.weight False\n",
      "bert.encoder.layer.4.output.LayerNorm.bias False\n",
      "bert.encoder.layer.5.attention.self.query.weight False\n",
      "bert.encoder.layer.5.attention.self.query.bias False\n",
      "bert.encoder.layer.5.attention.self.key.weight False\n",
      "bert.encoder.layer.5.attention.self.key.bias False\n",
      "bert.encoder.layer.5.attention.self.value.weight False\n",
      "bert.encoder.layer.5.attention.self.value.bias False\n",
      "bert.encoder.layer.5.attention.output.dense.weight False\n",
      "bert.encoder.layer.5.attention.output.dense.bias False\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight False\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias False\n",
      "bert.encoder.layer.5.intermediate.dense.weight False\n",
      "bert.encoder.layer.5.intermediate.dense.bias False\n",
      "bert.encoder.layer.5.output.dense.weight False\n",
      "bert.encoder.layer.5.output.dense.bias False\n",
      "bert.encoder.layer.5.output.LayerNorm.weight False\n",
      "bert.encoder.layer.5.output.LayerNorm.bias False\n",
      "bert.encoder.layer.6.attention.self.query.weight False\n",
      "bert.encoder.layer.6.attention.self.query.bias False\n",
      "bert.encoder.layer.6.attention.self.key.weight False\n",
      "bert.encoder.layer.6.attention.self.key.bias False\n",
      "bert.encoder.layer.6.attention.self.value.weight False\n",
      "bert.encoder.layer.6.attention.self.value.bias False\n",
      "bert.encoder.layer.6.attention.output.dense.weight False\n",
      "bert.encoder.layer.6.attention.output.dense.bias False\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight False\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias False\n",
      "bert.encoder.layer.6.intermediate.dense.weight False\n",
      "bert.encoder.layer.6.intermediate.dense.bias False\n",
      "bert.encoder.layer.6.output.dense.weight False\n",
      "bert.encoder.layer.6.output.dense.bias False\n",
      "bert.encoder.layer.6.output.LayerNorm.weight False\n",
      "bert.encoder.layer.6.output.LayerNorm.bias False\n",
      "bert.encoder.layer.7.attention.self.query.weight False\n",
      "bert.encoder.layer.7.attention.self.query.bias False\n",
      "bert.encoder.layer.7.attention.self.key.weight False\n",
      "bert.encoder.layer.7.attention.self.key.bias False\n",
      "bert.encoder.layer.7.attention.self.value.weight False\n",
      "bert.encoder.layer.7.attention.self.value.bias False\n",
      "bert.encoder.layer.7.attention.output.dense.weight False\n",
      "bert.encoder.layer.7.attention.output.dense.bias False\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight False\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias False\n",
      "bert.encoder.layer.7.intermediate.dense.weight False\n",
      "bert.encoder.layer.7.intermediate.dense.bias False\n",
      "bert.encoder.layer.7.output.dense.weight False\n",
      "bert.encoder.layer.7.output.dense.bias False\n",
      "bert.encoder.layer.7.output.LayerNorm.weight False\n",
      "bert.encoder.layer.7.output.LayerNorm.bias False\n",
      "bert.encoder.layer.8.attention.self.query.weight False\n",
      "bert.encoder.layer.8.attention.self.query.bias False\n",
      "bert.encoder.layer.8.attention.self.key.weight False\n",
      "bert.encoder.layer.8.attention.self.key.bias False\n",
      "bert.encoder.layer.8.attention.self.value.weight False\n",
      "bert.encoder.layer.8.attention.self.value.bias False\n",
      "bert.encoder.layer.8.attention.output.dense.weight False\n",
      "bert.encoder.layer.8.attention.output.dense.bias False\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight False\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias False\n",
      "bert.encoder.layer.8.intermediate.dense.weight False\n",
      "bert.encoder.layer.8.intermediate.dense.bias False\n",
      "bert.encoder.layer.8.output.dense.weight False\n",
      "bert.encoder.layer.8.output.dense.bias False\n",
      "bert.encoder.layer.8.output.LayerNorm.weight False\n",
      "bert.encoder.layer.8.output.LayerNorm.bias False\n",
      "bert.encoder.layer.9.attention.self.query.weight False\n",
      "bert.encoder.layer.9.attention.self.query.bias False\n",
      "bert.encoder.layer.9.attention.self.key.weight False\n",
      "bert.encoder.layer.9.attention.self.key.bias False\n",
      "bert.encoder.layer.9.attention.self.value.weight False\n",
      "bert.encoder.layer.9.attention.self.value.bias False\n",
      "bert.encoder.layer.9.attention.output.dense.weight False\n",
      "bert.encoder.layer.9.attention.output.dense.bias False\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight False\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias False\n",
      "bert.encoder.layer.9.intermediate.dense.weight False\n",
      "bert.encoder.layer.9.intermediate.dense.bias False\n",
      "bert.encoder.layer.9.output.dense.weight False\n",
      "bert.encoder.layer.9.output.dense.bias False\n",
      "bert.encoder.layer.9.output.LayerNorm.weight False\n",
      "bert.encoder.layer.9.output.LayerNorm.bias False\n",
      "bert.encoder.layer.10.attention.self.query.weight False\n",
      "bert.encoder.layer.10.attention.self.query.bias False\n",
      "bert.encoder.layer.10.attention.self.key.weight False\n",
      "bert.encoder.layer.10.attention.self.key.bias False\n",
      "bert.encoder.layer.10.attention.self.value.weight False\n",
      "bert.encoder.layer.10.attention.self.value.bias False\n",
      "bert.encoder.layer.10.attention.output.dense.weight False\n",
      "bert.encoder.layer.10.attention.output.dense.bias False\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight False\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias False\n",
      "bert.encoder.layer.10.intermediate.dense.weight False\n",
      "bert.encoder.layer.10.intermediate.dense.bias False\n",
      "bert.encoder.layer.10.output.dense.weight False\n",
      "bert.encoder.layer.10.output.dense.bias False\n",
      "bert.encoder.layer.10.output.LayerNorm.weight False\n",
      "bert.encoder.layer.10.output.LayerNorm.bias False\n",
      "bert.encoder.layer.11.attention.self.query.weight False\n",
      "bert.encoder.layer.11.attention.self.query.bias False\n",
      "bert.encoder.layer.11.attention.self.key.weight False\n",
      "bert.encoder.layer.11.attention.self.key.bias False\n",
      "bert.encoder.layer.11.attention.self.value.weight False\n",
      "bert.encoder.layer.11.attention.self.value.bias False\n",
      "bert.encoder.layer.11.attention.output.dense.weight False\n",
      "bert.encoder.layer.11.attention.output.dense.bias False\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight False\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias False\n",
      "bert.encoder.layer.11.intermediate.dense.weight False\n",
      "bert.encoder.layer.11.intermediate.dense.bias False\n",
      "bert.encoder.layer.11.output.dense.weight False\n",
      "bert.encoder.layer.11.output.dense.bias False\n",
      "bert.encoder.layer.11.output.LayerNorm.weight False\n",
      "bert.encoder.layer.11.output.LayerNorm.bias False\n",
      "bert.pooler.dense.weight False\n",
      "bert.pooler.dense.bias False\n",
      "classifier.weight False\n",
      "classifier.bias False\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, \n",
    "                                                           config=dataset_config).to(device)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if name.startswith(\"bert.encoder.layer\"): # choose whatever you like here\n",
    "        param.requires_grad = False\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c151c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
